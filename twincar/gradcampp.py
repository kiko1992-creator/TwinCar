# -*- coding: utf-8 -*-
"""gradcampp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVfY2BY0VwJab8dT3PiBZqVNUjt_zNAf
"""

"""
Grad-CAM++ implementation for model explainability

How to use:

1. Import:
    from twincar.modeling.gradcampp import GradCamPP, preprocess_image, overlay_cam_on_image

2. Instantiate:
    gradcam = GradCamPP(model, model.layer4[-1])  # for resnet50

3. Run and visualize:
    img_tensor = preprocess_image("path/to/image.jpg")
    cam = gradcam(img_tensor)
    vis_img = overlay_cam_on_image("path/to/image.jpg", cam)
    import cv2
    cv2.imwrite("gradcam_output.png", vis_img)
"""

import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2

def preprocess_image(img_path):
    tf = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])
    img = Image.open(img_path).convert('RGB')
    return tf(img).unsqueeze(0)

class GradCamPP:
    def __init__(self, model, target_layer):
        self.model = model
        self.model.eval()
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        self._register_hooks()

    def _register_hooks(self):
        def forward_hook(module, input, output):
            self.activations = output.detach()
        def backward_hook(module, grad_in, grad_out):
            self.gradients = grad_out[0].detach()
        self.target_layer.register_forward_hook(forward_hook)
        self.target_layer.register_backward_hook(backward_hook)

    def __call__(self, x, class_idx=None):
        output = self.model(x)
        if class_idx is None:
            class_idx = output.argmax(dim=1).item()
        loss = output[0, class_idx]
        self.model.zero_grad()
        loss.backward(retain_graph=True)

        gradients = self.gradients[0]    # [C, H, W]
        activations = self.activations[0] # [C, H, W]
        weights = self._get_weights(gradients, activations)
        cam = (weights[:, None, None] * activations).sum(0).cpu().numpy()
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (224, 224))
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        return cam

    def _get_weights(self, gradients, activations):
        grads_power_2 = gradients ** 2
        grads_power_3 = gradients ** 3
        sum_activations = torch.sum(activations, dim=(1, 2), keepdim=True)
        eps = 1e-8
        alpha_numer = grads_power_2
        alpha_denom = 2 * grads_power_2 + sum_activations * grads_power_3
        alpha_denom = torch.where(alpha_denom != 0.0, alpha_denom, torch.ones_like(alpha_denom) * eps)
        alphas = alpha_numer / (alpha_denom + eps)
        weights = torch.sum(alphas * F.relu(gradients), dim=(1, 2))
        return weights

def overlay_cam_on_image(img_path, cam, alpha=0.5):
    img = cv2.imread(img_path)
    img = cv2.resize(img, (224, 224))
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)
    return overlay

# Example usage (uncomment to run as script):
# from torchvision import models
# model = models.resnet50(weights=None)
# model.fc = torch.nn.Linear(model.fc.in_features, 196)
# model.load_state_dict(torch.load("models/resnet50_finetuned.pth", map_location="cpu"))
# model.eval()
# gradcam = GradCamPP(model, model.layer4[-1])
# img_tensor = preprocess_image("path/to/image.jpg")
# cam = gradcam(img_tensor)
# vis_img = overlay_cam_on_image("path/to/image.jpg", cam)
# import cv2
# cv2.imwrite("gradcam_output.png", vis_img)