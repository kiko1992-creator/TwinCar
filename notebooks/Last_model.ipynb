{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "🚗 TwinCar Project: SOTA Training, Full Visuals, and Advanced Reporting\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a0ZBAxe0bXOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Environment Setup and Imports\n",
        "Explanation:\n",
        "We start by importing all necessary libraries and prepping our working environment for advanced data handling and visualization.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bPASaByebhG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 1: Environment Setup and Imports\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, hamming_loss,\n",
        "    cohen_kappa_score, matthews_corrcoef, jaccard_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "import timm\n",
        "import scipy.io\n"
      ],
      "metadata": {
        "id": "vA0sxHiWiJSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Extraction and Preparation\n",
        "Explanation:\n",
        "We extract and organize the Stanford Cars dataset, parse .mat files to CSV for class and label mapping, and prepare all paths.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tzULBAPcbonR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 2: Data Extraction and Preparation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/stanford_cars.zip'\n",
        "extract_dir = '/content/stanford_cars'\n",
        "if not os.path.exists(extract_dir):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "print(\"✅ Dataset extracted at\", extract_dir)\n",
        "\n",
        "meta = scipy.io.loadmat(f\"{extract_dir}/car_devkit/devkit/cars_meta.mat\")\n",
        "class_names = [x[0] for x in meta['class_names'][0]]\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "train_annos = scipy.io.loadmat(f\"{extract_dir}/car_devkit/devkit/cars_train_annos.mat\")['annotations'][0]\n",
        "train_rows = [[x[5][0], int(x[4][0]) - 1] for x in train_annos]\n",
        "df_train = pd.DataFrame(train_rows, columns=[\"filename\", \"label\"])\n",
        "df_train.to_csv('/content/train_labels.csv', index=False)\n",
        "\n",
        "test_annos = scipy.io.loadmat(f\"{extract_dir}/car_devkit/devkit/cars_test_annos.mat\")['annotations'][0]\n",
        "test_rows = [[x[4][0]] for x in test_annos]\n",
        "df_test = pd.DataFrame(test_rows, columns=[\"filename\"])\n",
        "df_test.to_csv('/content/test_labels.csv', index=False)\n",
        "\n",
        "train_root = f\"{extract_dir}/cars_train/cars_train\"\n",
        "test_root = f\"{extract_dir}/cars_test/cars_test\"\n"
      ],
      "metadata": {
        "id": "2PbYf-0NiK9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Advanced Dataset and Augmentations\n",
        "Explanation:\n",
        "We build a flexible dataset class, apply advanced augmentations, and lay the foundation for Mixup/CutMix later.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cbsjk1E2cBkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 3: Dataset and Advanced Augmentations\n",
        "\n",
        "class StanfordCarsFromCSV(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, transform=None, has_labels=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.has_labels = has_labels\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.root_dir, row['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.has_labels:\n",
        "            return image, int(row['label'])\n",
        "        return image, row['filename']\n",
        "\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.2),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "])"
      ],
      "metadata": {
        "id": "G5OmzLPDiMhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Data Splitting, Weighted Sampling, and DataLoader\n",
        "Explanation:\n",
        "We split the data into train and validation sets with stratification for balanced classes,\n",
        "use class weighting to counter imbalance, and create PyTorch DataLoaders for efficient training and evaluation.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oO0V9Pe5cHQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Data Splitting, Loader Setup, and Weighted Sampling\n",
        "\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# --- Settings ---\n",
        "BATCH_SIZE = 32\n",
        "VAL_RATIO = 0.1\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# --- Stratified Split for Balanced Classes ---\n",
        "df_all = pd.read_csv('/content/train_labels.csv')\n",
        "df_train, df_val = train_test_split(\n",
        "    df_all,\n",
        "    test_size=VAL_RATIO,\n",
        "    stratify=df_all['label'],\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "df_train.to_csv('/content/train_split.csv', index=False)\n",
        "df_val.to_csv('/content/val_split.csv', index=False)\n",
        "\n",
        "# --- Datasets ---\n",
        "train_dataset = StanfordCarsFromCSV(train_root, '/content/train_split.csv', train_transform)\n",
        "val_dataset = StanfordCarsFromCSV(train_root, '/content/val_split.csv', val_transform)\n",
        "test_dataset = StanfordCarsFromCSV(test_root, '/content/test_labels.csv', val_transform, has_labels=False)\n",
        "\n",
        "# --- Weighted Sampler for Balanced Training ---\n",
        "labels = [label for _, label in train_dataset]\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
        "sample_weights = [class_weights[label] for label in labels]\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "# --- DataLoaders (drop_last=True for Mixup/CutMix compatibility) ---\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)} | Test samples: {len(test_dataset)}\")\n",
        "print(f\"Train loader batches (per epoch): {len(train_loader)} (should be integer and even-sized)\")"
      ],
      "metadata": {
        "id": "eRMzI9P5iQbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Initialization: EfficientNetV2 + Mixup/CutMix Ready\n",
        "Explanation:\n",
        "We load EfficientNetV2 with ImageNet weights for best transfer learning,\n",
        "set up optimizer, scheduler, and prepare for Mixup/CutMix advanced augmentation.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rRlHWMJAcs_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 5: Model Initialization (EfficientNetV2 + Mixup/CutMix)\n",
        "\n",
        "from timm.data import Mixup\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = timm.create_model('efficientnetv2_rw_s', pretrained=True, num_classes=NUM_CLASSES, drop_rate=0.3)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
        "\n",
        "mixup_fn = Mixup(\n",
        "    mixup_alpha=0.4, cutmix_alpha=1.0, cutmix_minmax=None,\n",
        "    prob=1.0, switch_prob=0.5, mode='batch',\n",
        "    label_smoothing=0.1, num_classes=NUM_CLASSES\n",
        ")"
      ],
      "metadata": {
        "id": "jFQEmTPCiRHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Advanced Training Loop: Full Metrics, Early Stopping, and Mixup\n",
        "Explanation:\n",
        "This loop supports Mixup/CutMix, logs all advanced metrics, and uses early stopping with automatic best model saving.\n",
        "Ready for real production—and all your plots and reporting.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HJlzWR9jczcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 6: Advanced Training Loop\n",
        "\n",
        "EPOCHS = 25\n",
        "patience, counter = 7, 0\n",
        "best_val_f1 = 0\n",
        "\n",
        "metrics_dict = {\n",
        "    'train_loss': [], 'train_acc': [],\n",
        "    'val_loss': [], 'val_acc': [],\n",
        "    'val_precision_macro': [], 'val_precision_weighted': [],\n",
        "    'val_recall_macro': [], 'val_recall_weighted': [],\n",
        "    'val_f1_macro': [], 'val_f1_weighted': [],\n",
        "    'val_hamming': [], 'val_cohen_kappa': [],\n",
        "    'val_mcc': [], 'val_jaccard_macro': [],\n",
        "    'val_top3': [], 'val_top5': [],\n",
        "}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        imgs, labels = mixup_fn(imgs, labels)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        correct += (outputs.argmax(1) == labels.argmax(1)).sum().item()\n",
        "        total += labels.size(0)\n",
        "    train_loss = total_loss / total\n",
        "    train_acc = correct / total\n",
        "    metrics_dict['train_loss'].append(train_loss)\n",
        "    metrics_dict['train_acc'].append(train_acc)\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "    val_probs, val_preds, val_targets = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(val_loader, desc=f\"Val Epoch {epoch+1}\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            v_loss = criterion(outputs, labels)\n",
        "            val_loss += v_loss.item() * imgs.size(0)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = outputs.argmax(1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "            val_probs.extend(probs.cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_targets.extend(labels.cpu().numpy())\n",
        "    val_loss /= val_total\n",
        "    val_acc = val_correct / val_total\n",
        "    val_preds_np = np.array(val_preds)\n",
        "    val_targets_np = np.array(val_targets)\n",
        "    val_probs_np = np.array(val_probs)\n",
        "\n",
        "    # Metrics\n",
        "    val_precision_macro = precision_score(val_targets_np, val_preds_np, average='macro', zero_division=0)\n",
        "    val_precision_weighted = precision_score(val_targets_np, val_preds_np, average='weighted', zero_division=0)\n",
        "    val_recall_macro = recall_score(val_targets_np, val_preds_np, average='macro', zero_division=0)\n",
        "    val_recall_weighted = recall_score(val_targets_np, val_preds_np, average='weighted', zero_division=0)\n",
        "    val_f1_macro = f1_score(val_targets_np, val_preds_np, average='macro', zero_division=0)\n",
        "    val_f1_weighted = f1_score(val_targets_np, val_preds_np, average='weighted', zero_division=0)\n",
        "    top3_acc = np.mean([\n",
        "        label in np.argsort(prob)[-3:] for prob, label in zip(val_probs_np, val_targets_np)\n",
        "    ])\n",
        "    top5_acc = np.mean([\n",
        "        label in np.argsort(prob)[-5:] for prob, label in zip(val_probs_np, val_targets_np)\n",
        "    ])\n",
        "    val_hamming = hamming_loss(val_targets_np, val_preds_np)\n",
        "    val_cohen_kappa = cohen_kappa_score(val_targets_np, val_preds_np)\n",
        "    val_mcc = matthews_corrcoef(val_targets_np, val_preds_np)\n",
        "    val_jaccard_macro = jaccard_score(val_targets_np, val_preds_np, average='macro', zero_division=0)\n",
        "\n",
        "    # Log metrics\n",
        "    metrics_dict['val_loss'].append(val_loss)\n",
        "    metrics_dict['val_acc'].append(val_acc)\n",
        "    metrics_dict['val_precision_macro'].append(val_precision_macro)\n",
        "    metrics_dict['val_precision_weighted'].append(val_precision_weighted)\n",
        "    metrics_dict['val_recall_macro'].append(val_recall_macro)\n",
        "    metrics_dict['val_recall_weighted'].append(val_recall_weighted)\n",
        "    metrics_dict['val_f1_macro'].append(val_f1_macro)\n",
        "    metrics_dict['val_f1_weighted'].append(val_f1_weighted)\n",
        "    metrics_dict['val_hamming'].append(val_hamming)\n",
        "    metrics_dict['val_cohen_kappa'].append(val_cohen_kappa)\n",
        "    metrics_dict['val_mcc'].append(val_mcc)\n",
        "    metrics_dict['val_jaccard_macro'].append(val_jaccard_macro)\n",
        "    metrics_dict['val_top3'].append(top3_acc)\n",
        "    metrics_dict['val_top5'].append(top5_acc)\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1:2d} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | F1(macro): {val_f1_macro:.4f} | Top3: {top3_acc:.3f} | Top5: {top5_acc:.3f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if val_f1_macro > best_val_f1:\n",
        "        best_val_f1 = val_f1_macro\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/efficientnetv2_best_model.pth')\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "print(\"✅ Training complete. Best model saved.\")"
      ],
      "metadata": {
        "id": "gxl72Kyci6-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Explanation\n",
        "After training, all metrics (accuracy, loss, precision, recall, F1, top-k, etc.) are saved as a CSV for analysis and reporting.\n",
        "\n",
        "We plot core metrics (accuracy, F1, loss, precision/recall, top-3/top-5 accuracy) with:\n",
        "\n",
        "Large, clear fonts\n",
        "\n",
        "Annotations for best epoch\n",
        "\n",
        "Colorful, pro-style Seaborn plots\n",
        "\n",
        "Publication-ready grid and tight layouts\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V5ktk4Fec5SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Metrics Export & Advanced Visualizations\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Save all metrics for reproducibility and later analysis\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "metrics_df.to_csv('/content/drive/MyDrive/metrics_log.csv', index_label='epoch')\n",
        "print(\"✅ metrics_log.csv saved.\")\n",
        "\n",
        "sns.set(style='whitegrid', font_scale=1.3)\n",
        "\n",
        "# 1. Accuracy & Macro F1\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(metrics_df['train_acc'], label='Train Acc', lw=2)\n",
        "plt.plot(metrics_df['val_acc'], label='Val Acc', lw=2)\n",
        "plt.plot(metrics_df['val_f1_macro'], label='Val F1 (macro)', lw=2)\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Score', fontsize=16)\n",
        "plt.title('Accuracy and Macro F1 per Epoch', fontsize=18)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "best_epoch = metrics_df['val_f1_macro'].idxmax()\n",
        "plt.scatter(best_epoch, metrics_df['val_f1_macro'][best_epoch], c='red', s=90, label='Best Epoch')\n",
        "plt.annotate(f'Best\\n{metrics_df[\"val_f1_macro\"][best_epoch]:.2f}',\n",
        "             (best_epoch, metrics_df[\"val_f1_macro\"][best_epoch]),\n",
        "             textcoords=\"offset points\", xytext=(-5,10), ha='right', fontsize=14, color='red')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/metrics_acc_f1_beautiful.png')\n",
        "plt.show()\n",
        "\n",
        "# 2. Loss Curves\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(metrics_df['train_loss'], label='Train Loss', lw=2)\n",
        "plt.plot(metrics_df['val_loss'], label='Val Loss', lw=2)\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Train & Validation Loss per Epoch', fontsize=18)\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/metrics_loss_beautiful.png')\n",
        "plt.show()\n",
        "\n",
        "# 3. Precision & Recall (Macro & Weighted)\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(metrics_df['val_precision_macro'], label='Val Precision (macro)', lw=2)\n",
        "plt.plot(metrics_df['val_recall_macro'], label='Val Recall (macro)', lw=2)\n",
        "plt.plot(metrics_df['val_precision_weighted'], label='Val Precision (weighted)', lw=2)\n",
        "plt.plot(metrics_df['val_recall_weighted'], label='Val Recall (weighted)', lw=2)\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Score', fontsize=16)\n",
        "plt.title('Validation Precision & Recall per Epoch', fontsize=18)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/metrics_precision_recall_beautiful.png')\n",
        "plt.show()\n",
        "\n",
        "# 4. Top-3 and Top-5 Validation Accuracy as Area Plot\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.fill_between(metrics_df.index, metrics_df['val_top3'], alpha=0.3, label='Val Top-3 Acc')\n",
        "plt.fill_between(metrics_df.index, metrics_df['val_top5'], alpha=0.2, label='Val Top-5 Acc', color='orange')\n",
        "plt.plot(metrics_df['val_top3'], lw=2, color='blue')\n",
        "plt.plot(metrics_df['val_top5'], lw=2, color='orange')\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Top-3 and Top-5 Validation Accuracy per Epoch', fontsize=18)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/metrics_topk_beautiful.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3R95y5_ziT03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Confusion Matrix & Per-Class Analysis with Advanced Visuals\n",
        "Explanation\n",
        "After training, it's crucial to understand not just overall metrics, but where your model succeeds and fails.\n",
        "We:\n",
        "\n",
        "Save a detailed classification report (per-class precision/recall/F1).\n",
        "\n",
        "Draw a high-contrast confusion matrix with large ticks, tight color scaling, and readable value overlays.\n",
        "\n",
        "Plot Top 20 Most Confused Classes for targeted debugging.\n",
        "\n",
        "Show Top 20 Most Accurate Classes with horizontal barplots (values on bars, sorted).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jqxoLkAkefPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Confusion Matrix & Per-Class Analysis (Advanced Visuals)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Reload best model for evaluation\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/efficientnetv2_best_model.pth', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Collect all validation predictions and true labels\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Save detailed classification report (per-class)\n",
        "report = classification_report(\n",
        "    all_labels, all_preds, target_names=class_names, output_dict=True\n",
        ")\n",
        "pd.DataFrame(report).transpose().to_csv('/content/drive/MyDrive/classification_report.csv')\n",
        "print(\"✅ classification_report.csv saved.\")\n",
        "\n",
        "# Confusion Matrix (full, high-res)\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(18,18))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    square=True,\n",
        "    cbar_kws={\"shrink\": 0.5, \"label\": \"Count\"},\n",
        "    linewidths=.2\n",
        ")\n",
        "plt.title('Confusion Matrix', fontsize=20)\n",
        "plt.xlabel('Predicted label', fontsize=16)\n",
        "plt.ylabel('True label', fontsize=16)\n",
        "plt.xticks(fontsize=8, rotation=90)\n",
        "plt.yticks(fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/confusion_matrix_beautiful.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Most Confused Classes (Top 20, value overlays)\n",
        "off_diag = cm.copy()\n",
        "np.fill_diagonal(off_diag, 0)\n",
        "most_confused = np.argsort(off_diag.sum(axis=1))[::-1][:20]\n",
        "cm_top = cm[np.ix_(most_confused, most_confused)]\n",
        "labels_top = [class_names[i] for i in most_confused]\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(\n",
        "    cm_top,\n",
        "    annot=True, fmt='d', cmap=\"Blues\",\n",
        "    xticklabels=labels_top, yticklabels=labels_top,\n",
        "    linewidths=.2, cbar=False, annot_kws={\"size\":14}\n",
        ")\n",
        "plt.title('Most Confused Classes (Top 20)', fontsize=18)\n",
        "plt.xlabel('Predicted label', fontsize=15)\n",
        "plt.ylabel('True label', fontsize=15)\n",
        "plt.xticks(fontsize=11, rotation=90)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/confused_top20_beautiful.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Top-20 Most Accurate Classes (barplot, values on bars)\n",
        "acc_per_class = cm.diagonal() / (cm.sum(axis=1) + 1e-8)\n",
        "df_acc = pd.DataFrame({'class': class_names, 'accuracy': acc_per_class})\n",
        "top_acc = df_acc.sort_values('accuracy', ascending=False).head(20)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.barplot(\n",
        "    data=top_acc, y='class', x='accuracy', palette='Blues_d', orient='h'\n",
        ")\n",
        "plt.title('Top 20 Classes by Accuracy', fontsize=18)\n",
        "plt.xlabel('Accuracy', fontsize=15)\n",
        "plt.ylabel('Class', fontsize=15)\n",
        "for i, v in enumerate(top_acc['accuracy']):\n",
        "    plt.text(v + 0.01, i, f\"{v:.2f}\", color='blue', va='center', fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/top20_accuracy_beautiful.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bfth26_Uk1wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Test-Time Augmentation (TTA) & Batch Prediction\n",
        "Explanation\n",
        "Test-Time Augmentation boosts prediction robustness by averaging predictions over multiple random transformations of each test image.\n",
        "Batch Prediction allows you to efficiently label a folder of test images with class names—production style."
      ],
      "metadata": {
        "id": "GyNkd0Cveop1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Test-Time Augmentation (TTA) for Validation\n",
        "\n",
        "tta_transforms = [\n",
        "    val_transform,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "    ])\n",
        "]\n",
        "\n",
        "def tta_predict(model, img_pil, tta_transforms, device='cuda'):\n",
        "    model.eval()\n",
        "    logits = []\n",
        "    for tform in tta_transforms:\n",
        "        img = tform(img_pil).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            logit = model(img)\n",
        "            logits.append(logit)\n",
        "    avg_logits = torch.stack(logits).mean(0)\n",
        "    return avg_logits\n",
        "\n",
        "# Apply TTA to validation set\n",
        "tta_val_preds, tta_val_labels = [], []\n",
        "for imgs, labels in tqdm(val_loader, desc=\"TTA Validation\"):\n",
        "    batch_preds = []\n",
        "    for i in range(imgs.size(0)):\n",
        "        img_pil = transforms.ToPILImage()(imgs[i].cpu())\n",
        "        avg_logits = tta_predict(model, img_pil, tta_transforms, device)\n",
        "        pred = avg_logits.argmax(dim=1).cpu().item()\n",
        "        batch_preds.append(pred)\n",
        "    tta_val_preds.extend(batch_preds)\n",
        "    tta_val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "tta_val_preds = np.array(tta_val_preds)\n",
        "tta_val_labels = np.array(tta_val_labels)\n",
        "\n",
        "# Metrics for TTA\n",
        "tta_f1_macro = f1_score(tta_val_labels, tta_val_preds, average='macro', zero_division=0)\n",
        "tta_acc = accuracy_score(tta_val_labels, tta_val_preds)\n",
        "tta_precision = precision_score(tta_val_labels, tta_val_preds, average='macro', zero_division=0)\n",
        "tta_recall = recall_score(tta_val_labels, tta_val_preds, average='macro', zero_division=0)\n",
        "print(f\"TTA Validation Accuracy: {tta_acc:.4f}\")\n",
        "print(f\"TTA Validation F1 (macro): {tta_f1_macro:.4f}\")\n",
        "print(f\"TTA Validation Precision (macro): {tta_precision:.4f}\")\n",
        "print(f\"TTA Validation Recall (macro): {tta_recall:.4f}\")\n",
        "\n",
        "# TTA Confusion matrix (optional)\n",
        "cm_tta = confusion_matrix(tta_val_labels, tta_val_preds)\n",
        "plt.figure(figsize=(18,18))\n",
        "sns.heatmap(\n",
        "    cm_tta,\n",
        "    cmap=\"Purples\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    square=True,\n",
        "    cbar_kws={\"shrink\": 0.5, \"label\": \"Count\"},\n",
        "    linewidths=.2\n",
        ")\n",
        "plt.title('TTA Confusion Matrix (Validation)', fontsize=20)\n",
        "plt.xlabel('Predicted label', fontsize=16)\n",
        "plt.ylabel('True label', fontsize=16)\n",
        "plt.xticks(fontsize=8, rotation=90)\n",
        "plt.yticks(fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/tta_confusion_matrix_beautiful.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-59H3ryck4v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Extraordinary Grad-CAM++ Overlays (Grid)\n",
        "Explanation\n",
        "We generate Grad-CAM++ visualizations for a set of sample images.\n",
        "Each visualization shows:The input image,The Grad-CAM++ heatmap overlay,The true and predicted class for easy comparison.\n",
        "All visualizations are saved both individually and as a large, labeled grid.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "D_o2DOktmrxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM++ Explanations: Multi-Image Grid (Fixed for latest grad-cam)\n",
        "!pip install -U grad-cam --quiet\n",
        "\n",
        "from pytorch_grad_cam import GradCAMPlusPlus\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/gradcam_outputs', exist_ok=True)\n",
        "\n",
        "# Make sure model is on the right device\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Pick the right target layer for EfficientNetV2 (last block)\n",
        "target_layer = model.blocks[-1] if hasattr(model, \"blocks\") else model.layer4[-1]\n",
        "\n",
        "# No more use_cuda argument—just instantiate\n",
        "cam = GradCAMPlusPlus(model=model, target_layers=[target_layer])\n",
        "\n",
        "num_images = 12\n",
        "fig, axes = plt.subplots(3, 4, figsize=(18, 14))\n",
        "fig.suptitle('Grad-CAM++ Explanations: True vs. Predicted', fontsize=22, weight='bold')\n",
        "\n",
        "for idx in range(num_images):\n",
        "    img_tensor, label = val_dataset[idx]\n",
        "    img_pil = transforms.ToPILImage()(img_tensor.cpu())\n",
        "    input_tensor = img_tensor.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred = output.argmax(1).item()\n",
        "    targets = [ClassifierOutputTarget(pred)]\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]\n",
        "    image_np = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    image_np = (image_np * np.array(imagenet_std)) + np.array(imagenet_mean)\n",
        "    image_np = np.clip(image_np, 0, 1)\n",
        "    cam_image = show_cam_on_image(image_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    # Save each Grad-CAM overlay individually\n",
        "    overlay_path = f\"/content/drive/MyDrive/gradcam_outputs/val_{idx}_true_{class_names[label]}_pred_{class_names[pred]}.png\"\n",
        "    plt.imsave(overlay_path, cam_image)\n",
        "\n",
        "    # Add to grid\n",
        "    ax = axes[idx // 4, idx % 4]\n",
        "    ax.imshow(cam_image)\n",
        "    ax.set_title(\n",
        "        f\"True: {class_names[label][:18]}\\nPred: {class_names[pred][:18]}\",\n",
        "        fontsize=12,\n",
        "        color=\"green\" if pred == label else \"red\",\n",
        "        weight=\"bold\"\n",
        "    )\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.savefig('/content/drive/MyDrive/gradcam_outputs/gradcam_grid.png', dpi=250)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q27a8RhvwkSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Gradio Interactive Demo: Model + Grad-CAM++"
      ],
      "metadata": {
        "id": "FwB89-Gsm9mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Gradio Interactive Demo: EfficientNetV2 + Grad-CAM++\n",
        "\n",
        "import gradio as gr\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "def predict_and_explain(img):\n",
        "    image_pil = img.convert(\"RGB\").resize((224, 224))\n",
        "    input_tensor = val_transform(image_pil).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_idx = output.argmax().item()\n",
        "    targets = [ClassifierOutputTarget(pred_idx)]\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]\n",
        "    image_np = np.array(image_pil).astype(np.float32) / 255.0\n",
        "    cam_image = show_cam_on_image(image_np, grayscale_cam, use_rgb=True)\n",
        "    pred_name = class_names[pred_idx]\n",
        "    return PILImage.fromarray(cam_image), f\"Prediction: {pred_name} (class index {pred_idx})\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_and_explain,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Car Image\"),\n",
        "    outputs=[gr.Image(label=\"Grad-CAM++ Output\"), gr.Text(label=\"Prediction\")],\n",
        "    title=\"🚗 TwinCar: Car Make/Model Classifier + Explainability Demo\",\n",
        "    description=\"Upload a car photo. See the prediction (make/model/year) and a Grad-CAM++ heatmap showing what influenced the model.\",\n",
        "    allow_flagging='never'\n",
        ")\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "G6O3sgPdk5x2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}